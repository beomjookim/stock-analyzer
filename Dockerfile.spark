FROM bitnami/spark:3.3.1

USER root

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    python3-pip \
    curl \
    apt-transport-https \
    ca-certificates \
    gnupg \
    openjdk-11-jdk

# GCP SDK ì„¤ì¹˜
RUN curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
    echo "deb https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
    apt-get update && apt-get install -y google-cloud-sdk

# 1. Spark JAR ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /opt/spark/jars

# 2. GCS Hadoop Connector ë‹¤ìš´ë¡œë“œ
RUN curl -o /opt/spark/jars/gcs-connector-hadoop3-2.2.5.jar https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-2.2.5.jar

# 3. Hadoop AWS JAR ì¶”ê°€ (í•„ìš”í•  ê²½ìš°)
RUN curl -o /opt/spark/jars/hadoop-aws-3.2.0.jar https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar
RUN curl -o /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.375/aws-java-sdk-bundle-1.11.375.jar

# Python ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
RUN pip3 install --no-cache-dir \
    google-cloud-storage \
    yfinance \
    pandas \
    requests \
    beautifulsoup4 \
    pyspark

# ðŸ”¹ GCS ì¸ì¦ ìžë™í™”
ENV GOOGLE_APPLICATION_CREDENTIALS="/opt/keys/gcs-key.json"
RUN echo 'gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS' >> ~/.bashrc

# Spark ì„¤ì • ì¶”ê°€
ENV SPARK_CLASSPATH="/opt/spark/jars/gcs-connector-hadoop3-2.2.5.jar:/opt/spark/jars/hadoop-aws-3.2.0.jar:/opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar"

RUN echo "spark.jars=/opt/spark/jars/gcs-connector-hadoop3-2.2.5.jar" >> /opt/bitnami/spark/conf/spark-defaults.conf
RUN echo "spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem" >> /opt/bitnami/spark/conf/spark-defaults.conf
RUN echo "spark.hadoop.fs.gs.auth.service.account.enable=true" >> /opt/bitnami/spark/conf/spark-defaults.conf
RUN echo "spark.hadoop.google.cloud.auth.service.account.json.keyfile=/opt/keys/gcs-key.json" >> /opt/bitnami/spark/conf/spark-defaults.conf

# ìž‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /opt/spark

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY ./src /opt/spark/src

# spark-master ì‹¤í–‰
CMD ["/opt/bitnami/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"]
